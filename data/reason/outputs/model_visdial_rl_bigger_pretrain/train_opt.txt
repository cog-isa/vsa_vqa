| options
run_dir: ../data/reason/outputs/model_visdial_rl_bigger_pretrain
dataset: clevr
shuffle: 1
num_workers: 1
manual_seed: None
gpu_ids: [0]
visualize: 0
clevr_train_scene_path: ../data/raw/visdial/raw/coco_trainval_scenes.json
clevr_val_scene_path: ../data/raw/visdial/raw/coco_trainval_scenes.json
clevr_train_question_path: ../data/raw/visdial/h5/visdial_unannotated_questions_train.h5
clevr_val_question_path: ../data/raw/visdial/h5/visdial_unannotated_questions_val.h5
clevr_vocab_path: ../data/raw/visdial/raw/visdial_vocab.json
max_train_samples: None
max_val_samples: 10000
load_checkpoint_path: ../data/reason/outputs/model_visdial_bigger_pretrain/checkpoint_best.pt
encoder_max_len: 50
decoder_max_len: 27
hidden_size: 256
word_vec_dim: 300
input_dropout_p: 0
dropout_p: 0
n_layers: 2
rnn_cell: lstm
bidirectional: 1
variable_lengths: 1
use_attention: 1
use_input_embedding: 0
fix_input_embedding: 0
start_id: 1
end_id: 2
null_id: 0
word2vec_path: None
fix_embedding: 0
reinforce: 1
vsa: 0
vsa_pretrain: 0
vsa_pretrain_steps: 100000
ppo: 0
batch_size: 64
learning_rate: 1e-05
entropy_factor: 0.0
num_iters: 1000000
reward_decay: 0.9
display_every: 20
checkpoint_every: 2000
visualize_training: 0
